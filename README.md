# ğŸ¤– LangChain + Hugging Face Integration

This repository demonstrates how to build a conversational AI application using [LangChain](https://github.com/langchain-ai/langchain) and [Hugging Face](https://huggingface.co) models. It includes working examples for querying hosted models via Hugging Face Inference API and using open-source models like TinyLlama locally in Colab.

## ğŸ”§ Features

- Integration with Hugging Face's Inference API via `langchain-huggingface`
- Support for hosted chat and text-generation models
- Local inference with `transformers` for models not hosted on Hugging Face
- Google Colab-friendly setup (no `.env` required)
- Simple LLM invocation examples using `LangChain`

## ğŸš€ Quick Start

### ğŸ“ Clone the Repo

```bash
git clone https://github.com/your-username/langchain-huggingface-example.git
cd langchain-huggingface-example
